[{"authors":["admin"],"categories":null,"content":"I am an Engineer and I love Engineering. Whether in a professional context dealing with software and electrical systems or at home as an amateur gardener setting up a micro spray system for a vegetable garden, I love the challenge of finding and implementing practical, efficient and effective solutions to real-world problems using systematic techniques coupled with creativity.\nI have a keen interest in the development of systems and technologies that blend mechanical, electrical and electronic systems with software-based computation and the application of computational intelligence to problems in general.\nProfessionally, my primary interest is Software Engineering, creating software systems that solve real-world problems and improve reliability, robustness and efficiency through automation. Peripherally, I am interested in helping businesses formalise and automate their workflows and secure their information to help ensure processes are efficient, effective, repeatable and reliable.\nUnderneath it all, I simply like making things that solve problems, both my own and those of others. In another time, I perhaps may have been a blacksmith.\n My hammer is a keyboard, my anvil a workstation, and my steel is an alloy of ones and zeros.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an Engineer and I love Engineering. Whether in a professional context dealing with software and electrical systems or at home as an amateur gardener setting up a micro spray system for a vegetable garden, I love the challenge of finding and implementing practical, efficient and effective solutions to real-world problems using systematic techniques coupled with creativity.","tags":null,"title":"David Fernandez","type":"authors"},{"authors":null,"categories":null,"content":"This website uses Google Analytics. For details, please refer to How Google uses information from sites or apps that use our services – Privacy \u0026amp; Terms – Google.\n","date":1583650800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583650800,"objectID":"18d05a63a1c8d7ed973cc51838494e41","permalink":"/privacy/","publishdate":"2020-03-08T18:00:00+11:00","relpermalink":"/privacy/","section":"","summary":"This website uses Google Analytics. For details, please refer to How Google uses information from sites or apps that use our services – Privacy \u0026amp; Terms – Google.","tags":null,"title":"Privacy Policy","type":"page"},{"authors":[],"categories":[],"content":"I have a need to use a single virtual machine on two devices, in particular a laptop and a desktop machine. My requirements/constraints for use are as follows:\n Both devices run Windows 10, so the solution must work in this environment. I do not need to work on both devices simultaneously. I will generally only use one device on any given day (i.e., will switch devices at most once per day). I do not wish for complications or performance hits within work sessions. I don\u0026rsquo;t mind some up-front complications. I don\u0026rsquo;t mind some performance hits (e.g., extra time) between work sessions. I almost exclusively use Vagrant by HashiCorp to manage my virtual machines, and VirtualBox by Oracle as the hypervisor, so my solution must work with these tools.  Broadly, this rules out solutions like working from an external drive (I don\u0026rsquo;t, for example, want to need to drag the drive around with me if I need to move the laptop to another area for a short time), but allows for a solution that requires data to be copied between devices when switching devices.\nThe process I\u0026rsquo;ve engineered to achieve this is initially convoluted, but it seems to work. The complications are primarily during initial setup; thereafter there\u0026rsquo;s not much to do beyond copy/sync files, and for that I\u0026rsquo;ve found FreeFileSync to be very useful.\nSetup/Initialisation  Ensure the box is explicitly given a name, such that it will be identical on all devices within VirtualBox, i.e., within the Vagrantfile:  config.vm.provider \u0026quot;virtualbox\u0026quot; do |vb|\rvb.name = \u0026quot;\u0026lt;machine-name\u0026gt;\u0026quot;\r Ensure the exact same VirtualBox path is used on both machines.   In my use, the laptop and desktop are quite differently configured. In particular, the laptop has a single drive and working partition (the ubiquitous C:) while the desktop has a multitude of drives and partitions, with my virtual machines residing on F:. To allow the same path to be used on both machines, I use a drive-mapped folder (see Map a Folder to a Drive Letter for Quick and Easy Access • Raymond.CC), using the same drive on both devices but different mapped folders. e.g.:\n Desktop: V: \u0026ndash;\u0026gt; \\??\\F:\\davidfernandez\\Virtualisation\\Machines\\VirtualBox Laptop: V: \u0026ndash;\u0026gt; \\??\\C:\\Users\\davidfernandez\\Virtualisation\\Machines\\VirtualBox    I use the registry-based method described in the article linked above, so an appropriate .reg file for the desktop would be:\n    Windows Registry Editor Version 5.00\r[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Session Manager\\DOS Devices]\r\u0026quot;V:\u0026quot;=\u0026quot;\\\\??\\\\F:\\\\davidfernandez\\\\Virtualisation\\\\Machines\\\\VirtualBox\u0026quot;\r On Device A, create the box via vagrant up.  If using the folder mapping trick (above), change VirtualBox's machine folder before creating the machine:  VBoxManage.exe setproperty machinefolder V:   Remember to reset/revert this afterwards.   Perform provisioning steps on Device A as required. On Device B, create the box via vagrant up, but (for efficiency) do not provision.  Again, if using folder mapping, change VirtualBox's machine folder before creating the machine.   Transfer material from Device A to Device B:  All VirtualBox files (e.g., *.vbox, *.vmdk etc.) All .vagrant/machines/\u0026lt;machine-name\u0026gt; files except:  .vagrant/machines/\u0026lt;machine-name\u0026gt;/virtualbox/synced_folders .vagrant/machines/\u0026lt;machine-name\u0026gt;/virtualbox/vagrant_cwd     These files contain device-specific paths (the host location of shared folders and the host location of the Vagrant project) and are best left matched to the device.   On Device B:  Replace the uuid value for the MachineRegistry/MachineEntry entry for the box in ~/.VirtualBox/VirtualBox.xml to match the value in the corresponding file on Device A. In other words, this XML element should be the same on both device\u0026rsquo;s configuration, with the existing uuid on Device A use in both:    \u0026lt;MachineEntry uuid=\u0026quot;{4b62d0e5-cf93-48de-8be2-460562b87fbf}\u0026quot; src=\u0026quot;V:\\\u0026lt;machine-name\u0026gt;\\\u0026lt;machine-name\u0026gt;.vbox\u0026quot;/\u0026gt;\r Notes This seems to break vagrant's ability to connect via ssh (i.e., specifically vagrant ssh fails, seeming due to a bad keypair). However, as I don\u0026rsquo;t use vagrant's ssh capabilities (that is, I connect via ssh using other tools), this doesn\u0026rsquo;t bother me and I have not spent time trying to resolve this. If you know what might be causing this specifically, and/or know a solution, let me know so I can update this post.\nOngoing Sync Thereafter, it should be sufficient to simply synchronise the files listed in step 6 above.\nTo improve efficiency of syncing, I find it useful to use snapshots. Without this, synchronising means (possibly1) transferring all virtual disk files/data. Using snapshots means you only transfer the virtual disks changed after the most recent snapshot.\nConclusion The setup steps for this arrangement are a bit fiddly, but only need to be done once (per machine you wish to synchronise). Thereafter, maintaining synchronicity is quite straightforward. I\u0026rsquo;ve been using this setup for a while now, and, other than the non-working vagrant-based ssh, everything works as expected. Hopefully this setup can be of use to you.\n  Depending on how smart your synchronisation tool is. Some tools, like rsync, will only transfer the parts/chunks of files that are different, and therefore are much more efficient than those that transfer the entire content of files that are different. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1583205569,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583205569,"objectID":"af053a6b7f7d5a30faa58f98fb23d546","permalink":"/post/synchronising_a_virtual_machine_across_devices/","publishdate":"2020-03-03T14:19:29+11:00","relpermalink":"/post/synchronising_a_virtual_machine_across_devices/","section":"post","summary":"I have a need to use a single virtual machine on two devices, in particular a laptop and a desktop machine. My requirements/constraints for use are as follows:\n Both devices run Windows 10, so the solution must work in this environment.","tags":["virtualisation"],"title":"Synchronising a Virtual Machine Across Devices","type":"post"},{"authors":[],"categories":[],"content":"This post describes the broad approach I have taken to setting-up and configuring the software system of my current primary home server (Mammoth). Much of this might seem overkill for a home lab, but part of the point of having a home lab is having a place and projects in and with which I can practice, refine and extend my skills and knowledge in areas that might otherwise be considered the domain of a \u0026ldquo;professional\u0026rdquo;, of some sort1.\nI won\u0026rsquo;t be presenting any code or code-like material here (that may come in subsequent posts), but will instead focus on my choice of tooling and methods. Also, note that this isn\u0026rsquo;t a tutorial on how to use any of these tools \u0026ndash; your favourite search engine will find those for you \u0026ndash; but rather a higher-level picture of how these different tools can be used together to solve a larger problem.\nOverview In general, I\u0026rsquo;m not a big fan of ad-hoc management of systems (e.g., servers) that handle anything remotely important. I like to automate (which then becomes documentation of sorts) and version-control. This aids greatly in problem-solving (if something goes wrong, the automation side can tell you exactly what was done, the revision control can let you go back to a working state) and repeatability (you might not ever need an exact duplicate of a system, but in my experience there are very often shared subsets).\nI do, however, like the ability to experiment and play before settling on a solution, especially when I\u0026rsquo;m working with something new and unfamiliar. Having a way to try something, knowing you can either undo what you\u0026rsquo;ve done if you\u0026rsquo;re not happy, or be able to exactly replicate if you are, is invaluable.\nTo achieve this, I make use of virtualisation technologies and automated provisioning systems.\nVirtualisation Virtualisation is used to provide what is essentially a simulated2 copy of the real environment. Within this environment, you can freely change things without worrying about messing up an otherwise functioning system. Using features like snapshotting, you can also create \u0026ldquo;known good\u0026rdquo; bookmarks of the system, that is, complete copies of the system state, to which you can return if and when required. In this manner, you can develop iteratively and progressively:\ngraph TB;\rA(Base System)\rB[Create Snapshot]\rC[Revert Snapshot]\rD(Snapshot)\rE[Modify]\rF{Happy?}\rG{Complete?}\rH(Done!)\rA -- B\rB -- D\rC -- D\rD -- E\rE -- F\rF -- no -- C\rF -- yes -- G\rG -- no -- B\rG -- yes -- H\r You essentially develop within a loop, starting with a known-good snapshot (which is initially created from whatever your starting point is), making changes, and either creating a new snapshot (if you\u0026rsquo;re happy with the changes) or reverting to the prior snapshot state (undoing) if you\u0026rsquo;re not happy. Rinse and repeat until your snapshot is your desired end state.\nBecause the system is virtual, and the snapshots are complete system states, you can afford to be as aggressive in your experimenting as you like. Completely messed up the (virtual) partition table? Meh. Revert.\nAn important caveat to this is that a virtual system will only be an approximation of the real system in terms of hardware. For many use-cases, perhaps most, this will be close enough. Limiting the available resources (disk space, RAM, CPU) within the virtual machine to match the real system can be plenty good enough (e.g., can let you know if you\u0026rsquo;re pushing the system beyond what the real machine could handle). If, however, your system involves some particular hardware (not just that the system has some particular hardware, but that your use of it requires that particular hardware), then the virtual machine may not suffice.\nTo reiterate, virtualisation provides a controlled and reproduceable environment and context for development and experimentation.\nAutomated Provisioning Automated provisioning is the process of using programmable tools to perform a variety of system setup operations, largely installing and configuring software packages. The notion of programmable tools here means you programatically define \u0026ndash; whether by scripts, \u0026ldquo;recipes\u0026rdquo;, or some form of configuration file \u0026ndash; what the tool should do. For example, to create a set of users, you might define a list of user specifications (each comprising a username, initial password and e-mail address) and specify that a \u0026ldquo;new user\u0026rdquo; operation be performed for each member of that list.\nIn this manner, the system is provisioned \u0026ndash; e.g., users are created \u0026ndash; according to a program that can be applied consistently. There is no need to remember the details of each user, nor the process of creating them. Especially when combined with a staging environment3 such as the virtual machine described above, this method and mechanisms can provide a high degree of reliability and quality assurance, as the programmatic nature removes a key source of problems: human error4.\nThe automated provisioning process becomes the work performed in the \u0026ldquo;Modify\u0026rdquo; block in the diagram above.\nThat\u0026rsquo;s How I Role Having provided a broad, non-specific overview , I\u0026rsquo;ll now describe some of the details of my preferred approach.\nIt is also important to note that other solution exist. In particular, the tools I present here are those I\u0026rsquo;ve come to know and love. I find them to be very good at their jobs and very happily recommend them, both individually and in combination, but it can\u0026rsquo;t hurt for you to explore alternatives and find things that suit you. The best tools are the ones you can use productively, and the reality is that often means the ones you like and not necessarily the ones that are technically superior. Find tools you\u0026rsquo;re happy to use, and spend time becoming proficient and productive with them.\nVirtualisation (again) There exist a variety of virtualisation tools that sit at different levels in the virtualisation hierarchy, with the software used to create and run virtual machines often referred to as a hypervisor. I won\u0026rsquo;t attempt to describe or define them here; places such as Wikipedia5 do a much better job. My long-term hypervisor preference is VirtualBox by Oracle. It works well on the host systems that interest me (Windows and Linux on x86 hardware) and can run virtual machines with the guest systems that interest me (again, Windows and Linux on x86 virtualised hardware). Also, it is free and open-source6, which appeals to me.\nMy general preference regarding virtual machines is to manage them via Vagrant by HashiCorp. Primarily, Vagrant is a tool to aid reproducability. It provides a means for defining, building and controlling virtual machines, sitting a level above the hypervisor. Among other things, it abstracts most areas of virtual machine creation and management such that dependence on a specific hypervisor is reduced7. A machine is defined via a configuration file that allows you to specify things like a base machine (e.g., a bare Ubuntu 18.04 installation) and resource tweaks (e.g., the amount of RAM, CPUs and such). This makes it very suitable for revision control (that is, the configuration can be placed under revision control), further aiding reproducibility.\nIn some cases, such as with Mammoth, a suitable base machine does not exist. Specifically, Mammoth uses a specific partitioning/filesystem layout that is not common enough for someone else to have created a matching base machine. This is where Packer by HashiCorp comes in. Packer is a tool for creating virtual machines from scratch. Whereas Vagrant requires an existing base machine (typically a minimally-configured machine with little more than a bare OS having been installed), Packer automates the process one would use to create that base machine (i.e., defining the base machine specs, such as RAM and disks, and automating OS installation and setup).\nNeither Packer nor Vagrant are tied to any particular virtual machine manager (such as VirtualBox).\nStep one, therefore, is to use Packer to create a base machine that resembles the real Mammoth as closely as possible. Mammoth uses the latest (18.04 at the time of its creation) long-term-support release of Ubuntu (server variant). To avoid reinventing the wheel, the Bento project was used as a starting point, removing things that weren\u0026rsquo;t needed (e.g., retaining only the ubuntu-18.04-amd64 template) and modifying to suit (e.g., specifying primary drive partitions and filesystems).\nAs a side note, I have had much success with Bento boxes, and highly recommend them for general use. Many of their boxes are available for direct use with Vagrant (i.e., without needing to build with Packer) at Vagrant Cloud.\nWith this base machine in place, Vagrant (and VirtualBox) can then be used to create and run working virtual machines.\nAutomated Provisioning (again) As with virtualisation, there are a variety of methods and tools to achieve automated provisioning, from freeform scripting through to dedicated tools. As you might guess, I like dedicated tools, and in particular, I like and use Ansible by Red Hat.\nOne of the primary reasons I prefer Ansible is its minimal requirements on both the control node (the machine doing the provisioning) and on managed nodes (the machines being provisioned). In the common case of provisioning a Linux machine, you simply need an SSH server and Python on the managed node8, and Python on the controller9. Ansible does not use or require a server/long-running process (beyond SSH) to run on the managed node (unlike a number of alternative tools), which is good for security (e.g., no additional ports to keep open or processes to keep secure) and resource use (e.g., no RAM or CPU time used by a process that is rarely used).\nI try to follow Ansible guidelines and best-practices as best as possible, which includes separating host specifications (\u0026ldquo;staging\u0026rdquo; points the the virtual machine, \u0026ldquo;production\u0026rdquo; points to the real machine), using playbooks for middle-management, and using roles to do the heavy lifting.\nUsing roles allows you to avoid reinventing the wheel as much as possible, either by making use of someone else\u0026rsquo;s role definitions (such as those available on Ansible Galaxy), or by creating something that you yourself can reuse on other projects (or publish if desired).\nI like to break provisioning up into sequential stages, with each stage corresponding to one iteration of the \u0026ldquo;snapshot -\u0026gt; change -\u0026gt; snapshot\u0026rdquo; loop described earlier. In this way, reverting to a snapshot during development means reverting to the result of running a particular sequence of playbooks/stages. I also like to keep stages short and logically coherent, such that they themselves may be reused on other projects.\n  And indeed, most of the things I describe here I learnt working as a software engineer. \u0026#x21a9;\u0026#xfe0e;\n I\u0026rsquo;m trying to give a description of things that is meaningful to a broad audience, not provide strictly-correct definitions. \u0026#x21a9;\u0026#xfe0e;\n With this sort of development work we often work in terms of different stages or environments: the production environment is the live, \u0026ldquo;real\u0026rdquo; system, the staging environment is as close an analogue as we can get to production where we perform final tests before applying changes to production, and the \u0026ldquo;development\u0026rdquo; environment is that in which most development work takes place before testing in \u0026ldquo;staging\u0026rdquo;. \u0026#x21a9;\u0026#xfe0e;\n Assuming one has effectively used the staging environment to develop and test the programs to iron out wrinkles. \u0026#x21a9;\u0026#xfe0e;\n See, for example, Virtualization - Wikipedia and Hypervisor - Wikipedia. \u0026#x21a9;\u0026#xfe0e;\n Except the extension pack, which is not open-source and, broadly speaking, is free for personal use but non-free for commercial user. See Licensing_FAQ – Oracle VM VirtualBox. \u0026#x21a9;\u0026#xfe0e;\n There are still some aspects of machine definition that depend on the specific hypervisor being used. \u0026#x21a9;\u0026#xfe0e;\n Which covers most if not all modern Linux distributions, including the default for Raspberry Pi machines. \u0026#x21a9;\u0026#xfe0e;\n Officially, Windows isn\u0026rsquo;t supported as a controller, though Windows Subsystem for Linux overcomes this limitation and is the way I use Ansible. \u0026#x21a9;\u0026#xfe0e;\n   ","date":1566081363,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1566081363,"objectID":"9d9a03883ba7b22ccb3386255a9056e8","permalink":"/post/homelab/virtualisation_and_provisioning/","publishdate":"2019-08-18T08:36:03+10:00","relpermalink":"/post/homelab/virtualisation_and_provisioning/","section":"post","summary":"This post describes the broad approach I have taken to setting-up and configuring the software system of my current primary home server (Mammoth). Much of this might seem overkill for a home lab, but part of the point of having a home lab is having a place and projects in and with which I can practice, refine and extend my skills and knowledge in areas that might otherwise be considered the domain of a \u0026ldquo;professional\u0026rdquo;, of some sort1.","tags":["homelab","virtualisation"],"title":"Virtualisation and Provisioning","type":"post"},{"authors":[],"categories":[],"content":"This project serves to capture material relating to my home (computer) lab setup. I intend to use this to document and share what I have done and learned and what I hope to do in future.\n","date":1565760195,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565760195,"objectID":"69febae6a5bb1a27ed550ec24ac538b8","permalink":"/project/homelab/","publishdate":"2019-08-14T15:23:15+10:00","relpermalink":"/project/homelab/","section":"project","summary":"This project serves to capture material relating to my home (computer) lab setup. I intend to use this to document and share what I have done and learned and what I hope to do in future.","tags":["homelab"],"title":"HomeLab","type":"project"},{"authors":[],"categories":[],"content":"Information Security is something that interests me. I would argue that it should be of interest to anyone and everyone involved in managing or handling data, especially that of other people1, which pretty much means almost everyone working in software development or information technology more generally. It should also include anyone making choices about what software or systems they use to manage data, even if that\u0026rsquo;s not part of their job description.\n\rTLDR;\nDefinitions As a first point, I should clarify what I mean by information security, as varying definitions exist. I tend to follow the definition provided in ISO/IEC 270002:\n definition 3.28: preservation of confidentiality, integrity and availability of information\n As noted in the footnote to that definition, other properties, such as authenticity and reliability, can also be involved, though, for the moment at least, I will maintain focus on the three above.\nThese properties will be relevant to all users of data, though the requirements can vary widely and this must be understood.\nIntegrity  definition 3.36: property of accuracy and completeness2\n Broadly speaking I consider data integrity to simply mean that the data is what you expect it to be, which generally means that, for a given piece of data, what you read tomorrow is what you3 wrote today.\nAlmost all users will have about the same integrity requirements: they want the data they retrieve to be the data they saved. They do not want the data to be changed in unexpected ways, whether as a result of malicious action (e.g., \u0026ldquo;hacking\u0026rdquo;), user error (e.g., accidental deletion), or system failure (e.g., a hardware crash).\nThat said, there may be some instances where this isn\u0026rsquo;t strictly true. An example may be an image storage system whereby uploaded images are (re-)compressed in a lossy manner (e.g., JPEG compression) in order to reduce size (and hence, perhaps, allow the user to store more images).4 In this case, what the user later retrieves (the compressed image) is not exactly bit-for-bit the same as that which they sent for storage.\nAvailability  definition 3.7: property of being accessible and usable on demand by an authorized entity2\n In simple terms, I consider this to mean that everyone that should have access to the data is able to get it in a timely manner.\nAvailability requirements will differ: some users will want/need data immediately5, some don\u0026rsquo;t mind to wait. All want to get it eventually though.\nConfidentiality  definition 3.10: property that information is not made available or disclosed to unauthorized individuals, entities, or processes2\n I consider this to mean that access to data \u0026ndash; including, in some cases, mere knowledge of the existence of the data \u0026ndash; can be restricted and controlled.\nConfidentiality requirements will differ: some don\u0026rsquo;t care who has access6, some want all to access (e.g., someone in marketing may want as many people as possible to view their pitch), some want strict controls (few people want anyone but themselves and perhaps their bank to see their bank records).\nAuthenticity One of the \u0026ldquo;other properties\u0026rdquo; mentioned in the opening information security definition that I\u0026rsquo;d like to expand on is authenticity.\n definition 3.6: property that an entity is what it claims to be2\n I like to think of this in terms of trust or provenance, that is, being able to trust, verify or confirm the stated source of data.\nAs with all the other properties, requirements will vary. In some instances, as long as access-control mechanisms are in place (i.e., only authorised users have access), it may not matter which specific authorised user has modified data. In other cases (such as a hospital patient\u0026rsquo;s medication requirements), knowing exactly which user made the changes \u0026ndash; and possibly knowing the entire change history \u0026ndash; is of critical importance.\nLax Approach (not the airport) Too often, it seems, information security is an afterthought. It isn\u0026rsquo;t often part of a user\u0026rsquo;s core requirements (they want to use the data to do things that are important to them), though this is changing as more people become aware of what can happen when information is not secured. As a result of this lack of user pressure, the need to keep information secure can fall by the wayside (market pressures can mean it is sometimes difficult to justify spending resources investigating/developing features that the user won\u0026rsquo;t explicitly demand).\nIn many instances, I believe that information security is seen as non-critical because of the parallels drawn with physical security, e.g., physical locks and keys on doors. By and large, physical security mechanisms exist to protect physical resources from theft, damage or other such malicious acts. To prioritise security of this form essentially requires belief that a) one has resources worth protecting, and b) there exist malicious others that would try to gain access to those resources. In the world of information, I suggest that most people can evaluate the first point well enough7, but perhaps don\u0026rsquo;t do so well with the second8.\nIn the physical world, generally, the cost of attempting to gain access to restricted resources (e.g., research time, time to break open a lock and door, the risk and consequence of being caught and so-on) is relatively high, so it makes sense that attackers would tend to choose targets relatively carefully such that the potential gains outweigh the potential costs. In the information world, however, the cost of attempting access can be exceptionally low, approaching zero when considering the scale of attack provided by mechanisms like botnets9 and when the global, cross-border nature of things means law enforcement is often powerless. In addition, as mechanisms such as ransomware10 have demonstrated, modes of attack that aren\u0026rsquo;t often seen in the physical world can become very attractive to attackers in the information world.\nThe consequence is that resources that would not be targets for attackers in the physical world are targets in the information world. As a result, I think that questions that might be relevant in physical security, such as \u0026ldquo;why would anyone want to steal my stuff?\u0026rdquo; or \u0026ldquo;who would go after me?\u0026rdquo; are not so useful when considering information security, as the broad answers that present real threats can simply be \u0026ldquo;because they can\u0026rdquo; and \u0026ldquo;anyone looking to make a quick buck\u0026rdquo;.\nIn short, to those without experience or interest in the area, the risks associated with poor information security are not generally as well understood or appreciated as those for physical security.\nMore Than Just Stopping The Bad Guys In the section above I focussed on the notion of protecting information from those seeking to do harm of some sort (theft, extortion, etc.), but information security is about more that just that. There are many ways, beyond malice, in which the security of information can be compromised, and these should be considered even, and perhaps especially, in cases where protection against attack is not considered important (e.g., within an isolated/offline system).\nOne source of compromise is plain old user error, or PICNIC11 as it\u0026rsquo;s sometimes known. I\u0026rsquo;d hazard a guess that almost everyone (if not everyone) who has ever used a computer has at some stage accidentally deleted a file. Or worse12.\nA second set of sources are system faults. This broad category covers many things including hardware failures, software crashes, natural disasters (e.g., floods that damage/destroy hardware) and unexpected user responses13.\nIn both cases there\u0026rsquo;s no ill intent, but that matters little if your critical data is gone.\nFor risks such as these, one really needs to be thinking beyond the threats with parallels in traditional (physical) security. It really isn\u0026rsquo;t just about \u0026ldquo;who are the bad guys and how could they get me?\u0026rdquo;, it\u0026rsquo;s about \u0026ldquo;how is my data at risk?\u0026rdquo;.\nPhilosophy With these definitions and ideas in mind, I present my philosophy:\n Information Security should be considered a foundational aspect of the specification and design of systems managing data.\n This isn\u0026rsquo;t revolutionary or outside the square, and I don\u0026rsquo;t expect my view is unique, but I don\u0026rsquo;t think it\u0026rsquo;s the norm yet either.\nAlso, I don\u0026rsquo;t mean that every system should have two-factor authentication, signed certificates, redundant storage, 256-bit encrypted channels or any other particular security feature. Rather, when specifying or designing such a system, the properties defined and described above should be explicitly considered and appropriate questions asked. \u0026ldquo;How is the information secured?\u0026rdquo; should be as important a question as \u0026ldquo;How much will this cost?\u0026rdquo;.\nAddressing information security concerns is fundamentally an exercise in risk management and so, if helpful, the language and tools of risk management can be used to aid in the determination of how information will be secured. This can be especially helpful for those that don\u0026rsquo;t have a background in information security (or information technology more generally) but are familiar with risk management (such as many in management roles).\nTakeaway I\u0026rsquo;ve taken a somewhat engineering- and slightly business-oriented approach to things here, but I firmly believe that these ideas are applicable to non-professionals too. I suggest that a person\u0026rsquo;s family photos are as valuable to them as financial records are to a business, and quite possibly more valuable.\nTo that end, I leave you with this:\n Any information that is of value to you is worth keeping secure.\n   My general view with this sort of thing is roughly this: if you mess up your own stuff, you have to deal with the consequences. If you mess up someone else\u0026rsquo;s stuff, they have to deal with the consequences, which I think is worse (i.e., having to clean up someone else\u0026rsquo;s mess). \u0026#x21a9;\u0026#xfe0e;\n \rISO/IEC 27000:2018 - Information technology \u0026ndash; Security techniques \u0026ndash; Information security management systems \u0026ndash; Overview and vocabulary \u0026#x21a9;\u0026#xfe0e;\n Or some other authorised user/process/agent. \u0026#x21a9;\u0026#xfe0e;\n Google Photos allows users to make such a choice. See Choose the upload size of your photos and videos - Google Photos Help \u0026#x21a9;\u0026#xfe0e;\n Even \u0026ldquo;immediately\u0026rdquo; can vary: for high-frequency traders, \u0026ldquo;immediately\u0026rdquo; can mean within microseconds of making a request, while for most people, waiting a few seconds to retrieve an email message is perfectly fine. \u0026#x21a9;\u0026#xfe0e;\n Though even this can vary, for example, between who can read the data and who can modify it. \u0026#x21a9;\u0026#xfe0e;\n Though I\u0026rsquo;d also suggest that too many people undervalue personal information that can be misused with regards to identity theft. \u0026#x21a9;\u0026#xfe0e;\n It\u0026rsquo;s not too uncommon to hear variations on \u0026ldquo;why would anyone want to go after me?\u0026rdquo;. \u0026#x21a9;\u0026#xfe0e;\n \rBotnet - Wikipedia \u0026#x21a9;\u0026#xfe0e;\n \rRansomware - Wikipedia \u0026#x21a9;\u0026#xfe0e;\n \rPEBCAK - Wiktionary \u0026#x21a9;\u0026#xfe0e;\n For example, these Six Horror Stories of Data Loss \u0026#x21a9;\u0026#xfe0e;\n Such as Unintentional Denial-of-service attack - Wikipedia \u0026#x21a9;\u0026#xfe0e;\n   ","date":1565490229,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565673358,"objectID":"150801da1873ee2f3470dcb202ad2ea0","permalink":"/post/infosec/information-security-00/","publishdate":"2019-08-11T12:23:49+10:00","relpermalink":"/post/infosec/information-security-00/","section":"post","summary":"Information Security is something that interests me. I would argue that it should be of interest to anyone and everyone involved in managing or handling data, especially that of other people1, which pretty much means almost everyone working in software development or information technology more generally.","tags":["infosec"],"title":"Information Security: My Philosophy","type":"post"},{"authors":[],"categories":[],"content":"This project serves to capture material pertaining to this website. It is a form of self-documentation, that may include things such as plans (what I\u0026rsquo;d like to add later), reviews (have things worked out the way I hoped?) and technical notes (descriptions of how I achieved certain effects, for example).\n","date":1565227715,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565227715,"objectID":"45ebec94239860b76c942aeeb8db8c2a","permalink":"/project/this_website/","publishdate":"2019-08-08T11:28:35+10:00","relpermalink":"/project/this_website/","section":"project","summary":"This project serves to capture material pertaining to this website. It is a form of self-documentation, that may include things such as plans (what I\u0026rsquo;d like to add later), reviews (have things worked out the way I hoped?","tags":["this website"],"title":"This Website","type":"project"},{"authors":[],"categories":[],"content":"I\u0026rsquo;m not sure which attempt this is. Only the second, I think. The last one was quite some time ago though. It chugged along ok for a while, but tapered off and dropped into oblivion. Hopefully this one sticks.\nI\u0026rsquo;m also not sure what I shall be posting here. A mix of things probably. I\u0026rsquo;d like to document some of my hobby projects, share some non-technical things (like parks and playgrounds I\u0026rsquo;ve discovered and enjoyed) and also describe some more serious professional points (like what services I can offer and how I can help you).\nWithout wishing to get too philosophical, it is said that A journey of a thousand miles begins with a single step1. This is that first step.\n  \rA journey of a thousand miles begins with a single step - Wikipedia \u0026#x21a9;\u0026#xfe0e;\n   ","date":1565150093,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1565150093,"objectID":"b557ca0247c8f13d3bb1c41741e2b85b","permalink":"/post/this_website/post_number_one/","publishdate":"2019-08-07T13:54:53+10:00","relpermalink":"/post/this_website/post_number_one/","section":"post","summary":"I\u0026rsquo;m not sure which attempt this is. Only the second, I think. The last one was quite some time ago though. It chugged along ok for a while, but tapered off and dropped into oblivion.","tags":["this website"],"title":"Post Number One","type":"post"},{"authors":["D. Fernandez","R. A. Jarvis"],"categories":[],"content":"","date":1197417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1197417600,"objectID":"6ae7e000a911f5c2f36eb2cf1fc19bd5","permalink":"/publication/local-path-planning-along-bush-tracks-using-vision/","publishdate":"2019-08-14T14:38:34+10:00","relpermalink":"/publication/local-path-planning-along-bush-tracks-using-vision/","section":"publication","summary":"This paper investigates the problem of autonomous mobile robot navigation in bush environments. Such environments form part of the workspace of a number of groups, such as rural search-and-rescue and bush fire-fighting crews, who could greatly benefit from helper robots. In particular, given the existence of many tracks through bush areas, the ability to autonomously drive along such tracks would help ensure robot safety and efficiency of travel, as a track by definition represents a passageway with a high likelihood of being clear. The novelty of the work presented comes from the sole use of passive vision to find obstacles and locate tracks, allowing a safe local path to be determined.","tags":[],"title":"Local Path Planning along Bush Tracks using Vision","type":"publication"},{"authors":["D. Fernandez"],"categories":[],"content":"","date":1177977600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1177977600,"objectID":"3ec0111429ee145c196314348670a058","permalink":"/publication/visual-navigation-on-rough-tracks-in-bush-environments/","publishdate":"2019-08-14T14:45:41+10:00","relpermalink":"/publication/visual-navigation-on-rough-tracks-in-bush-environments/","section":"publication","summary":"Natural environments can be very challenging workspaces for humans and machines. Unlike urban environments that are designed, built and maintained by man, natural environments can appear random and arbitrary, with little or none of the structure, regularity or consistency that so often makes even the simplest tasks achievable. Bush environments are essentially natural environments, though often some structure does exist in the form of the many rough tracks – often referred to simply as dirt roads – that have been cut into the landscape to allow easier access, sometimes for bushfire control, for example. These environments, typified by State and National Parks that cover much of Australia’s south-east regions, present a worth-while challenge to the field of robotics. These areas are the common workplace of a number of important groups, notably fire-fighters, search and rescue personnel and park and forest management personnel from Australian departments and authorities. Around the globe, similar local agencies – such as the California Department of Forestry and Fire Protection in the United States – perform largely the same duties in very similar environments. These people work in a difficult environment, often in time-critical and life-threatening operations. With a very small number of people trying to manage a very large area of land, help in the form of autonomous or semi-autonomous robots could be of great benefit.\n\nThe work presented in this thesis aims to address the problem of how navigation may be performed in bush environments, specifically navigation along poorly structured dirt roads. To be efficient (in terms of say energy consumption or mission time) and to give the highest chance of mission success, navigation should make use of roads whenever possible, as they are far more likely to offer safe and unhindered and hence rapid travel than the alternative of trekking cross-country. Because of the irregularity, inconsistency and low level of structure exhibited by dirt roads, traditional urban road-following techniques that make use of painted road markings and consistent road geometry are simply not applicable. Instead, alternative methods must be employed that can handle these and other uncontrollable environmental conditions. With the budgets of relevant agencies often stretched, cost is an important factor, as is mechanical simplicity. In balancing these requirements against adequate sensing requirements, the choice was made to use passive vision only, that is, only simple, cheap and commonly available cameras are to be used to provide the necessary input, coupled with standard computing equipment to perform processing. Comparatively expensive and often complex sensors using lasers, sonar or active vision are avoided.","tags":[],"title":"Visual navigation on rough tracks in bush environments","type":"publication"},{"authors":["D. Fernandez","A. Price"],"categories":[],"content":"","date":1121817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1121817600,"objectID":"d3126c5e53cc2c4f1475beebc465daf4","permalink":"/publication/visual-detection-and-tracking-of-poorly-structured-dirt-roads/","publishdate":"2019-08-14T14:32:38+10:00","relpermalink":"/publication/visual-detection-and-tracking-of-poorly-structured-dirt-roads/","section":"publication","summary":"Outdoor mobile robots are often faced with the problem of trying to navigate through an unknown environment. Areas that appear simple to humans can be very difficult for a robot to accurately and consistently describe. Poorly structured dirt roads, such as fire-access tracks and bush-walking tracks, are often overlooked in research but are highly important passageways for emergency support crews, such as search-and-rescue teams and firefighters tackling bush fires. This paper presents a method of autonomously detecting and hence tracking such roads using colour vision. Central to the process is a method of characterising the road surface through a statistical colour description, which makes minimal assumptions about the road. A highly simplified and generalised road model is used to ignore the background and contain the road, and weighted control points are used to generate a spline-based trajectory along the road, which is intended to be used for motion-control of a robot trying to traverse these tracks. Inherent to the system is the avoidance or safe traversal of certain types of obstacles. The combination of simple modelling and efficient processing algorithms has resulted in a usable average processing speed of approximately eight frames per second on the 1.7 GHz Pentium-4 test machine","tags":[],"title":"Visual detection and tracking of poorly structured dirt roads","type":"publication"},{"authors":["D. Fernandez","A. Price"],"categories":[],"content":"","date":1102032000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1102032000,"objectID":"dac3dd927423194f7eb45b888500df73","permalink":"/publication/visual-odometry-for-an-outdoor-mobile-robot/","publishdate":"2019-08-14T14:22:05+10:00","relpermalink":"/publication/visual-odometry-for-an-outdoor-mobile-robot/","section":"publication","summary":"This paper presents an alternative solution to the problem of estimating the motion of an outdoor mobile robot through odometry. The solution consists of the use of vision and pseudo-optical flow techniques to make motion estimates of a camera attached to the robot chassis. The use of vision makes the system independent of locomotion (for example, the differences between a robot with wheels and one with legs) and is shown to be applicable to a variety or outdoor ground surfaces, such as tarmac, gravel, grass and dirt. Finally, the simplified calculations result in high processing speeds on moderate equipment, with experiments showing that high speed motion (approximately 300 degree per second rotations and 350 millimetre per second translations) can be reliably estimated.","tags":[],"title":"Visual odometry for an outdoor mobile robot","type":"publication"}]